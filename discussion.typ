#import "base.typ": *

= Discussion <discus>

In this chapter, we will compare the two implementations of unification
(MM+SymPy and Equality Saturation) that we presented earlier. We will compare
multiple aspects: runtime performance, explainability, completeness and
soundness, and extensibility.

== Runtime performance <runtime>

The runtimes of solving $udata$ with either the MM-Algorithm or Equality
Saturation, as well as isolating metavariables (@rules-isol) with Equality
Saturation, are negligible. They all complete within tens of milliseconds. What
we will compare specifically here is algebraic simplification of natural number
terms. Before we do this, let us consider why simplification is necessary.
Returning smaller terms (with regard to AST size) from type inference than
without simplification is helpful to users, as the returned types might
otherwise not be easily readable. It also improves code generation for later
stages of #rise's compiler framework. Another potential usecase for
simplification is determining semantic equivalence of natural numbers as defined
by #smallcaps[R-NatEquiv] in @rise-builtin. If we had a simplification process
that was also _normalizing_#footnote[For example, we would need to normalize
  addition such that both $a+1+1$ and $3+a-1$ simplify into the normal form
  $2+a$, in order to assert syntactic equality.], we could use syntactic
equality to imply semantic equivalence, since two terms that are syntactically
equal must also mean the same thing. We could use this process to partially
prove semantic equivalence of our unification goals using equality saturation.
(Note that this does not fully prove semantic equivalence, since two normalized
terms that are not syntactically equal could still be semantically equivalent.
More on this in @complete.) However, we did not implement this due to the
discouraging runtime performance of equality saturation when performing
algebraic simplification, which we will discuss now. An alternative approach to
proving semantic equivalence using an SMT solver will be discussed in
@completesound.

@perf shows a comparison of both of our implementations. The input consists of
30 #r(
  "nat",
)-unification goals generated by one #rise program. One initial example goal
(after isolation) is
$
  meta(m) unat &#r("(- (- (* 2 (/ (- (+ 1 (+ (+ 1 (+ (/ (nat_bvar h_1) 2) 3)) 0)) 2) 1)) 1)")\ &#r("   (- (+ 2 (* 2 (/ (nat_bvar h_1) 2))) (nat_bvar h_1)))"),
$
which we refer to in the table. SymPy returns the fully simplified term (as well
as all other terms) after 600ms. For Equality Saturation, we show multiple rows
which differ by iteration count, i.e., for how many iterations our
simplification rules (@rules-simp) were applied. After 6 iterations and one
second, Equality Saturation resolves $meta(m)$ to #r(
  "(+ -1 (+ 4 (nat_bvar h_1)))",
), which is _almost_ fully simplified. Then, $meta(m)$ is not simplified further
until iteration 14. In total, 180 seconds are needed to fully simplify
$meta(m)$. Simplification of $meta(m)$ is paused in iterations 6--13, because
`egg` uses an exponential backoff scheduler by default. The scheduler will ban
certain rewrite rules for a number of iterations before attempting to match them
again, namely those rules which have matched many times in previous iterations.
This is a performance optimization that trades full exploration of the e-graph
for a better runtime performance, potentially leading to suboptimal results as
is the case here. The rewrite rule for associativity of addition is banned
during iterations 6--13, and is unbanned in iteration 14, which allows for
constant folding to take place. This also results in the 14th iteration taking a
much longer time. Note that when not using the backoff scheduler at all, initial
iterations take a much longer time, so using it is beneficial for us. However,
there may be a potential to optimize its configuration for our usecase.

#figure(
  caption: [Runtime performance comparison. SymPy completes within less than a
    second, while `egg` struggles to simplify terms within a reasonable
    timeframe due to rules such as associativity and commutativity drastically
    growing the e-graph. The stark time difference between iteration 13 and 14
    is due to `egg`'s backoff scheduler: Expensive rules are unbanned in
    iteration 14, which leads to a much higher runtime.],
  kind: table,
  placement: auto,
)[
  #{
    [*Input: 30 unification goals*]
    set align(center)
    [
      #grid(
        columns: 4,
        align: (center, center, right, right),
        gutter: 1em,
        grid.header([], [*Iterations*], [*Time*], [*$meta(m)$ resolves to*]),
        [SymPy], [/], [\~600ms], [#r("(+ (nat_bvar h_1) 3)")],
        // #pause
        // [],

        [egg],
        [2],
        [\~8ms],
        [#r("(+ (+ 2 (* 2 (+ (+ (/ (nat_bvar h_1) 2) 1) 1))) -3)")],

        [egg], [6], [\~1#h(.75pt)000ms], [#r("(+ -1 (+ 4 (nat_bvar h_1)))")],
        [egg], [13], [\~5#h(.75pt)000ms], [#r("(+ -1 (+ 4 (nat_bvar h_1)))")],
        [egg], [14], [\~180#h(.75pt)000ms], [#r("(+ (nat_bvar h_1) 3)")],
      )
    ]
  }
] <perf>

We find that Equality Saturation is not well-suited for arithmetic
simplification due to rules such as commutativity and associativity drastically
growing the e-graph, and resulting in full simplification taking too long to be
realistically used. As such, it is unsuitable to prove semantic equivalence by
syntactic equality. If semantic equivalence could be proven through other means
(e.g. by an SMT solver), we would not necessarily have to fully simplify #r(
  "nat",
)s. Nevertheless, returning only partially simplified #r("nat")s to the user is
still unsatisfying.

// The user having to wait for three minutes to typecheck an arguably simple #rise
// program is not acceptable. #q[rephrase] We will discuss potential solutions and
// alternatives in @future.

// #q[also dont know when we are done]


== Completeness & Soundness <completesound>
The correctness of an algorithm or formal system is commonly divided into
completeness and soundness. In our context, completeness of a unification
algorithm means: "If a unifier for a given set of unification goals exists, then
the algorithm finds one". (A unifier is a unifying substitution, i.e., one that
yields equality or semantic equivalence when applied to the unification goals.)
The converse of completeness is soundness, and means: "If the algorithm returns
a substitution $sigma$, then $sigma$ is a unifier of the unification goals".
Together, completeness and soundness form the biimplication of correctness: "The
algorithm returns a substitution $sigma$ if and only if $sigma$ is a unifier".
We say that the algorithm is correct. In @unif-mm, we introduced the algorithm
by #cp(
  <martelliEfficientUnificationAlgorithm1982>,
) to solve syntactic first-order unification (in our context $udata$), which is
known to be correct. However, solving $unat$ is fundamentally undecidable, i.e.,
there is no algorithm that always gives a correct answer. This is because
Hilbert's Tenth Problem was proven with a negative answer by Yuri Matiyasevich
in 1970 @murtyHilbertsTenthProblem2019. The problem asks whether there is an
algorithm determining whether an arbitrary Diophantine equation (a polynomial
equation with integral coefficients and any number of variables) has natural
number solutions #footnote[The original problem asks for integer solutions, but
  this is an equivalent formulation #cite(
    <murtyHilbertsTenthProblem2019>,
    supplement: "Chapter 5",
  ).]. #rise's #r("nat")s can express diophantine equations, since we can
reformulate a set of #r("nat")-unification goals (where no term uses division)
into a single Diophantine equation: Given ${a_1 unat b_1, ..., a_n unat b_n}$,
the respective Diophantine equation is $a_1 - b_1 + ... + a_n - b_n = 0$. Since
it is proven that no algorithm exists that determines whether an arbitrary
Diophantine equation is solvable, solving $unat$ is undecidable in general. This
means that no #r("nat")-unification algorithm can be complete, because it cannot
always decide whether a unifier for a given set of unification goals exists, and
therefore also cannot always find a unifier. Thus, we will use completeness
informally when referring to $unat$, restricting the terms to apply only to
unification goals encountered in practice, because no implementation can ever be
fully complete. We can however ascertain soundness, namely by only returning a
found substitution if we can prove that it results in semantic equivalence of
the unification goal, and otherwise fail (e.g. by returning "unknown").

We reiterate here that SymPy is not formally verified, but has been in
development for many years and has benefitted by many contributors improving it.
As such, we do trust its results, but can never be fully certain of them. Thus,
we will not discuss its guarantees further and instead focus on equality
saturation.

=== Completeness <complete>
As mentioned, #r("nat")-unification cannot be complete. Nevertheless, it is
worthwhile to consider additional caveats to completeness that we encountered,
but are not necessarily universal.

First and foremost, we want to address the definition of semantic equivalence,
which -- we think unintentionally -- prohibits a class of #rise programs and
hence restricts completeness of the #rise type system. In @rise-tyrules, we
defined semantic equivalence of natural number terms as
#align(center, ir(
  label: [R-NatEquiv],
  $forall sigma : op("dom")(Delta) -> NN thick . thick sigma(N) = sigma(M)$,
  $N equiv M$,
))

and indicated that we think the definition is flawed. To see why, consider the
following #rise program:
```rise
def mul : {t : data} → t → t → t

fun a : nat =>
fun xs : 4·f32 =>
fun ys : a·f32 =>
  (mul xs) ys
```
The program multiplies the values of an array of length #r("4") with the values
of an array of length #r("a"). In order for this program to be valid, the types
of #r("xs") and #r("ys") must be semantically equivalent (see #smallcaps[R-App]
in combination with #smallcaps[R-NatEquiv]), which implies that #r("4") and #r(
  "a",
) must be semantically equivalent. But #r("a") is a bound variable, and thus
will be in the kinding context $Delta$ for this derivation, so it is subject to
$sigma$ in #smallcaps[R-NatEquiv]. And clearly, it is not true that all
substitutions of #r("a") yield equality to #r("4")\; only the substitution
$[#r("a") |-> #r("4")]$ does. If we implemented this rule faithfully, the above
program would not typecheck. We do not think that this was intended by the #rise
authors, but rather that the intention of #smallcaps[R-NatEquiv] is to determine
that a term like $#r("a+5-2")$ is semantically equivalent to #r(
  "3+a",
), because it evaluates to the same natural number for all substitutions of #r(
  "a",
). But as shown here, the rule is flawed whenever a variable occurs on only one
side of a semantic equivalence, and not both. In that case, the equivalence
should be viewed as a constraint that the program imposes on the variable (such
as here, where #r("a") can only be #r("4")). This requires to remodel #rise's
type system to reason about constraints.

// To typecheck this program, one of the unification goals that will be generated
// is the #r("nat")-unification goal $bmv(a) unat 4$.

// The process described in @solve-unat is _almost_ complete
// for the currently implemented operations on #r("nat")s: #r("*"), #r("/"), #r(
//   "+",
// ), and #r(
//   "-",
// ).

One notable caveat of our equality saturation implementation pertains to
division by zero. In @solve-unat, we introduced rewrite rules constrained by a
condition not_zero(), for example
#box[$pvar(c) ~ pvar(a) dot pvar(b) -> pvar(c) slash pvar(b) ~ pvar(a) "if not_zero"(pvar(b))$].
This rule will not be applied if the e-class of $pvar(b)$ contains an e-node
with the constant value of $0$. However, implementing the condition as such is
not sufficient, because while the e-class may not contain $0$ at the time of the
rewrite, later iterations and further rewrites might find that the e-class does
in fact contain $0$ or is potentially equal to $0$, so the first rewrite should
never have been applied. Hence we need to err on the side of caution and "prove"
that e-class will never possibly contain zero (barring a general
unsatisfiability of the unification, where anything is possible). For example,
if the e-class contains a single nat_bvar, or various additions and
multiplications of constants and variables, we know that they will never be
rewritten to $0$. But if the e-class contains a term such as
$("nat_bvar n") - 5$, the rewrite should not be applied because that term is
potentially equal to $0$ depending on the value of $("nat_bvar n")$. This in
turn however means that we will not always be able to apply this rewrite rule,
and thus may not be able to isolate each metavariable. If we could ascertain
that (nat_bvar n) will never be $5$, we could apply the rewrite. In order to do
that, we would have to generalize our approach to reason about _constraints_,
and not only equalities, as we do currently.

//  We will speak more on this in
// @future.

// Ignoring any division-by-zero-issues, the rewrite rules for isolating
// metavariables (@rules-isol) are able to isolate each metavariable from all #r(
//   "nat",
// )-terms, and guarantee that every metavariable has exactly one solution.
// Additionally, the rules saturate the e-graph, so the process is terminating.
// #q[todo]

There is another caveat to our already restricted notion of completeness:
#rise's existing Scala implementation also supports other operations, for
example modulo. Given a unification goal of $nmv(x) thin % thin 2 unat 0$, it is
not possible to isolate $nmv(x)$, i.e., uniquely solve for $nmv(x)$. This is
only possible in our implementation because all supported operations have an
inverse. But here, one can only assert that $nmv(x)$ must be even. This again
hints at the necessity for reasoning about constraints.

As seen in this section, all mentioned caveats require reasoning about
constraints in #rise's type system. We will discuss this more in @future.
// , which we will discuss in
// @future.

=== Soundness
==== Discovering unsatisfiability of bound variables. <discover>
An ill-typed #rise program may generate the unification goal
$bmv(a)+bmv(b) unat bmv(a)-bmv(b)$, which is unsatisfiable since $bmv(b)$ must
be strictly positive and cannot be $0$. A possible procedure to discover this
type of unsatisfiability is to isolate $bmv(a)$ on the left to arrive at
$bmv(a) unat bmv(a)-bmv(b)-bmv(b)$, and notice that the right-hand side of the
unification goal contains $bmv(a)$ but cannot be simplified to being only
$bmv(a)$. This is the notion of "syntactic equality implies semantic
equivalence" described in @runtime. There are other kinds of unsatisfiability we
need to detect, such as having the unification goals
${bmv(a) unat 5, bmv(a) unat 3}$, where a different, holistic detection
procedure would be needed. Additionally, it is unclear (at least to us) how to
_guarantee_ that all types of unsatisfiability are discoverable at least in
principle. Thus we did not implement any such procedures but instead employed an
SMT solver to help with this. After having found a substitution with equality
saturation, we apply this substitution to the originating #r(
  "nat",
)-unification goals and generate an SMT program which asserts that for each
unification goal, the left- and right-hand side must be equal. This returns
either `unsat` in the case of unsatisfiability, a single valid assignment for
each nat_bvar contained in the unification goals, or `unknown` if neither could
be determined. The SMT solver's `sat` & `unsat` results can be fully trusted,
since it is based on formal logic, can produce formal proofs, and can be
independently verified.

// However, this likely does not cover all cases of unsatisfiability. A potential
// solution to this by employing an SMT solver is given in @future.



==== Erroneously equalizing metavariables.
As mentioned in @solve-unat, we need the following rule to solve for
metavariables, which sets equal any metavariable that is to be unified with any
other term: $("nat_mvar" pvar(a)) ~ pvar(b) |-> ("nat_mvar" pvar(a)) = pvar(b)$.
However, this rule can lead to equalizing terms in the e-graph that are
impossible to be equal. Consider the unification goals
#box[${nmv(m) & unat bmv(a)+bmv(b), nmv(n) & unat bmv(a)-bmv(b), nmv(m) & unat nmv(n)}$].
Applying the mentioned rule on these goals will lead to having
$bmv(a)+bmv(b) = bmv(a)-bmv(b)$ in the e-graph. If we want to avoid representing
unsatisfiable equalities in the e-graph, we need to prevent this rewrite from
happening in this case. This could be achieved with a condition, however it is
not clear how that condition should look like.

Summarizing this section on completeness and soundness of our process, there are
many caveats and open questions with regard to solving $unat$ and guaranteeing
correct results. Using an SMT solver to verify the results found by equality
saturation appears to be a viable alternative. As described, the solver will
only return a single assignment for each nat_bvar when the unification goals are
satisfiable, which is insufficient information. Instead, we would want it to
assert satisfiability for _all_ nat_bvars. We could potentially negate our
assertions such that a result of `unsat` intuitively means that _it is
impossible to find nat_bvars such that the assertions are false, so therefore
they must be true for all nat_bvars_, but we did not explore this path yet.

== Explainability
Since we are implementing a typechecking algorithm, we want to give feedback to
the user when a program fails to typecheck. This feedback needs to refer to the
specific application (i.e., unification goal) or applications which were not
satisfiable. To our knowledge, SymPy does not provide any mechanism to explain
which equalities of an equational system led to there being no solution. We did
not add soundness checks to our equality saturation implementation, so we cannot
confidently evaluate this aspect. Nevertheless, since we are fully in control of
our implementation, it is reasonable to assume that once an unsatisfiability
between one or more unification goals has been detected, we would be able to
report back precisely those unification goals. It is worth noting that this
approach is reminiscent of a feature of SMT solvers called _producing an
unsatisfiable core_, i.e., producing a minimal subset of the originating
formula's clauses that are unsatisfiable.


== Extensibility
As we established in @unif, with equality saturation we were able to both
implement $udata$ (syntactic first-order unification) and $unat$ (equational
unification), while SymPy was only suitable for $unat$. It should be no surprise
that we deem equality saturation to be more extensible than SymPy, since the
very premise of equality saturation is based on providing a custom language,
rewrite rules, and analysis, while SymPy is designed specifically for symbolic
mathematics. However, this advantage of equality saturation also has a price:
Every extension needs to be reasoned about, implemented, vetted, and possibly
optimized. Meanwhile, SymPy is a well-suited tool for the purpose of solving
$unat$ and only needed to be integrated into our typechecking algorithm.

We also need to consider in which _direction_ we want to extend. For example,
our implementation of $udata$ is in principle agnostic over which datatypes it
unifies. Adapting it to other datatypes is as trivial as adding variants to the
internal language, and adding simple rewrite rules. But looking beyond what we
implemented in this work, we hinted at the necessity for constraints in #rise's
type system (@complete), for example inequalities such as "$b$ must be larger
than $4$". To our knowledge, SymPy does not support adding such constraints to
an equational system. Similarly, E-Graphs are not well-suited to reason about
inequalities. After all, E stands for equality.

// #q[doesn't feel done but i dont know what else to say.]








