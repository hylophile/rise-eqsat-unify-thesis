#import "base.typ": *

= Discussion <discus>

In this chapter, we will compare the two implementations of unification
(MM+SymPy and Equality Saturation) that we presented earlier. We will compare
multiple aspects: runtime performance, explainability, completeness and
soundness, and extensibility.

== Runtime performance
// A type-checking algorithm needs to complete in a _reasonable_ time. While "reasonable" is a subjective measure,
// #q[]

// In @solve-unat, we already mentioned that we #q[]

The runtimes of solving $udata$ with either the MM-Algorithm or Equality
Saturation, as well as isolating metavariables (@rules-isol) with Equality
Saturation, are negligible. They all complete within tens of milliseconds. What
we will compare specifically here is the simplification process. @perf shows a
comparison of both of our implementations. The input consists of 30 #r(
  "nat",
)-unification goals generated by one #rise program. One initial example goal
(after isolation) is
$
  meta(m) unat &#r("(- (- (* 2 (/ (- (+ 1 (+ (+ 1 (+ (/ (nat_bvar h_1) 2) 3)) 0)) 2) 1)) 1)")\ &#r("   (- (+ 2 (* 2 (/ (nat_bvar h_1) 2))) (nat_bvar h_1)))"),
$
which we refer to in the table. SymPy returns the fully simplified term (as well
as all other terms) after 600ms. For Equality Saturation, we show multiple rows
which differ by iteration count, i.e., for how many iterations our
simplification rules (@rules-simp) were applied. After 6 iterations and one
second, Equality Saturation resolves $meta(m)$ to #r(
  "(+ -1 (+ 4 (nat_bvar h_1)))",
), which is _almost_ fully simplified. Then, the process gets stuck and our
setup needs 14 iterations and 180 seconds in total to fully simplify $meta(m)$.
Equality Saturation gets stuck because `egg` uses an exponential backoff
scheduler by default. The scheduler will ban certain rewrite rules for a number
of iterations before attempting to match them again, namely those rules which
have matched many times in previous iterations. This is a performance
optimization that trades full exploration of the e-graph for a better runtime
performance, potentially leading to suboptimal results as is the case here. The
rewrite rule for associativity of addition is banned during iterations 6-13, and
is unbanned in iteration 14, which allows for constant folding to take place.
This also results in the 14th iteration taking a much longer time. Note that
when not using the backoff scheduler at all, initial iterations take a much
longer time, so using it is beneficial for us. However, there may be a potential
to optimize its configuration for our usecase.

#figure(
  caption: [Runtime performance comparison. SymPy completes within less than a
    second, while `egg` struggles to simplify terms within a reasonable
    timeframe due to rules such as associativity and commutativity drastically
    growing the e-graph. The stark time difference between iteration 13 and 14
    is due to `egg`'s backoff scheduler: Expensive rules are unbanned in
    iteration 14, which leads to a much higher runtime.],
  kind: table,
  placement: auto,
)[
  #{
    [*Input: 30 unification goals*]
    set align(center)
    [
      #grid(
        columns: 4,
        align: (center, center, left, right),
        gutter: 1em,
        grid.header(
          [*Implementation*],
          [*Iterations*],
          [*Time*],
          [*$meta(m)$ resolves to*],
        ),
        [SymPy], [/], [\~600ms], [#r("(+ (nat_bvar h_1) 3)")],
        // #pause
        // [],

        [egg],
        [2],
        [\~8ms],
        [#r("(+ (+ 2 (* 2 (+ (+ (/ (nat_bvar h_1) 2) 1) 1))) -3)")],

        [egg], [6], [\~1s], [#r("(+ -1 (+ 4 (nat_bvar h_1)))")],
        [egg], [13], [\~5s], [#r("(+ -1 (+ 4 (nat_bvar h_1)))")],
        [egg], [14], [\~180s], [#r("(+ (nat_bvar h_1) 3)")],
      )
    ]
  }
] <perf>

We find that Equality Saturation is not well-suited for arithmetic
simplification due to rules such as commutativity and associativity drastically
growing the e-graph. The user having to wait for three minutes to typecheck an
arguably simple #rise program is not acceptable. We will discuss potential
solutions and alternatives in @future.

// #q[also dont know when we are done]


== Completeness & Soundness <completesound>
A formal system is considered complete if it can derive _all_ true statements of
that system, and sound if it _only_ derives true statements. In @unif-mm, we
introduced the algorithm by #cp(
  <martelliEfficientUnificationAlgorithm1982>,
) to solve syntactic first-order unification (in our context $udata$), which is
known to be sound and complete. However, solving $unat$ is fundamentally
undecidable, i.e., there is no algorithm that always gives a correct answer.
This is because Hilbert's Tenth Problem was proven with a negative answer by
Yuri Matiyasevich in 1970 @murtyHilbertsTenthProblem2019. The problem asks
whether there is an algorithm determining whether an arbitrary Diophantine
equation (a polynomial equation with integral coefficients and any number of
variables) has natural number solutions #footnote[The original problem asks for
  integer solutions, but this is an equivalent formulation #cite(
    <murtyHilbertsTenthProblem2019>,
    supplement: "Chapter 5",
  ).]. #rise's #r("nat")s can express diophantine equations, since we can
reformulate a set of #r("nat")-unification goals (where no term uses division)
into a single Diophantine equation: Given ${a_1 unat b_1, ..., a_n unat b_n}$,
the respective Diophantine equation is $a_1 - b_1 + ... + a_n - b_n = 0$. Since
it is proven that no algorithm exists that solves an arbitrary Diophantine
equation, solving $unat$ is undecidable in general.

Thus, we will use completeness and soundness informally when referring to
$unat$, restricting the terms to apply only to unification goals encountered in
practice, because no implementation can ever be fully complete or sound.
Completeness refers to the fact that an implementation is able to find a
substitution for each metavariable iff the originating program should typecheck
-- for those sets of #r("nat")-unification goals that we encounter in practice.
And analogously, soundness refers to the ability of an implementation to assert
that a particular set of unification goals (that is encountered in practice) is
unsatisfiable iff the originating program should not typecheck.

We reiterate here that SymPy is not formally verified, but has been in
development for many years and has benefitted by many contributors improving it.
As such, we do trust its results, but can never be fully certain of them. Thus,
we will not discuss its guarantees further and instead focus on equality
saturation.

=== Completeness <complete>
The process described in @solve-unat is _almost_ complete for the currently
implemented operations on #r("nat")s: #r("*"), #r("/"), #r("+"), and #r(
  "-",
). A notable exception pertains to division by zero. In @solve-unat, we
introduced rewrite rules constrained by a condition not_zero(), for example
#box[$pvar(c) ~ pvar(a) dot pvar(b) -> pvar(c) slash pvar(b) ~ pvar(a) "if not_zero"(pvar(b))$].
This rule will not be applied if the e-class of $pvar(b)$ contains an e-node
with the constant value of $0$. However, implementing the condition as such is
not sufficient, because while the e-class may not contain $0$ at the time of the
rewrite, later iterations and further rewrites might find that the e-class does
in fact contain $0$ or is potentially equal to $0$, so the first rewrite should
never have been applied. Hence we need to err on the side of caution and "prove"
that e-class will never possibly contain zero (barring a general
unsatisfiability of the unification, where anything is possible). For example,
if the e-class contains a single nat_bvar, or various additions and
multiplications of constants and variables, we know that they will never be
rewritten to $0$. But if the e-class contains a term such as
$("nat_bvar n") - 5$, the rewrite should not be applied because that term is
potentially equal to $0$ depending on the value of (nat_bvar n), ). This in turn
however means that we will not always be able to apply this rewrite rule, and
thus may not be able to isolate each metavariable. If we could ascertain that
(nat_bvar n) will never be $5$, we could apply the rewrite. In order to do that,
we would have to generalize our approach to reason about _constraints_, and not
only equalities, as we do currently. We will speak more on this in @future.
Ignoring any division-by-zero-issues, the rewrite rules for isolating
metavariables (@rules-isol) are able to isolate each metavariable from all #r(
  "nat",
)-terms, and guarantee that every metavariable has exactly one solution.
Additionally, the rules saturate the e-graph, so the process is terminating.

There is yet another caveat to our already highly restricted notion of
completeness: #rise's existing Scala implementation also supports other
operations, for example modulo. Given a unification goal of
$nmv(x) thin % thin 2 unat 0$, it is not possible to isolate $nmv(x)$, i.e.,
uniquely solve for $nmv(x)$. This is only possible in our implementation because
all supported operations have an inverse. But here, one can only assert that
$nmv(x)$ must be even. This again hints at the necessity for reasoning about
constraints, which we will discuss in @future.

=== Soundness
==== Discovering unsatisfiability.
An ill-typed #rise program may generate the unification goal
$bmv(a)+bmv(b) unat bmv(a)-bmv(b)$, which is unsatisfiable since $bmv(b)$ cannot
be $0$. A possible procedure to discover this type of unsatisfiability is to
isolate $bmv(a)$ on the left to arrive at $bmv(a) unat bmv(a)-bmv(b)-bmv(b)$,
and notice that the right-hand side of the unification goal contains $bmv(a)$
but cannot be simplified to being only $bmv(a)$. There are other kinds of
unsatisfiability we need to detect, such as having the unification goals
${bmv(a) unat 5, bmv(a) unat 3}$, where a different detection procedure would be
needed. Additionally, it is unclear (at least to us) how to _guarantee_ that all
types of unsatisfiability are discoverable at least in principle. Thus we did
not implement any such procedures but instead employed an SMT solver to help
with this. After having found a substitution with equality saturation, we apply
this substitution to the originating #r("nat")-unification goals and generate an
SMT program which asserts that for each unification goal, the left- and
right-hand side must be equal. This returns either `unsat` in the case of
unsatisfiability, a single valid assignment for each nat_bvar contained in the
unification goals, or `unknown` if neither could be determined. The SMT solver's
`sat` & `unsat` results can be fully trusted, since it is based on formal logic,
can produce formal proofs, and can be independently verified.

// However, this likely does not cover all cases of unsatisfiability. A potential
// solution to this by employing an SMT solver is given in @future.



==== Erroneously equalizing metavariables.
As mentioned in @solve-unat, we need the following rule to solve for
metavariables, which sets equal any metavariable that is to be unified with any
other term: $("nat_mvar" pvar(a)) ~ pvar(b) |-> ("nat_mvar" pvar(a)) = pvar(b)$.
However, this rule can lead to equalizing terms in the e-graph that are
impossible to be equal. Consider the unification goals
#box[${nmv(m) & unat bmv(a)+bmv(b), nmv(n) & unat bmv(a)-bmv(b), nmv(m) & unat nmv(n)}$].
Applying the mentioned rule on these goals will lead to having
$bmv(a)+bmv(b) = bmv(a)-bmv(b)$ in the e-graph. If we want to avoid representing
unsatisfiable equalities in the e-graph, we need to prevent this rewrite from
happening in this case. This could be achieved with a condition, however it is
not clear how that condition should look like.

Summarizing this section on completeness and soundness of our process, there are
many caveats and open questions with regard to solving $unat$ and guaranteeing
correct results. Using an SMT solver to verify the results found by equality
saturation appears to be a viable alternative. As described, the solver will
only return a single assignment for each nat_bvar when the unification goals are
satisfiable, which is insufficient information. Instead, we would want it to
assert satisfiability for _all_ nat_bvars. We could potentially negate our
assertions such that a result of `unsat` intuitively means that _it is
impossible to find nat_bvars such that the assertions are false, so therefore
they must be true for all nat_bvars_, but we did not explore this path yet.

== Explainability
Since we are implementing a typechecking algorithm, we want to give feedback to
the user when a program fails to typecheck. This feedback needs to refer to the
specific application (i.e., unification goal) or applications which were not
satisfiable. To our knowledge, SymPy does not provide any mechanism to explain
which equalities of an equational system led to there being no solution. We did
not add soundness checks to our equality saturation implementation, so we cannot
confidently evaluate this aspect. Nevertheless, since we are fully in control of
our implementation, it is reasonable to assume that once an unsatisfiability
between one or more unification goals has been detected, we would be able to
report back precisely those unification goals. It is worth noting that this
approach is reminiscent of a feature of SMT solvers called _producing an
unsatisfiable core_, i.e., producing a minimal subset of the originating
formula's clauses that are unsatisfiable.


== Extensibility
As we established in @unif, with equality saturation we were able to both
implement $udata$ (syntactic first-order unification) and $unat$ (equational
unification), while SymPy was only suitable for $unat$. It should be no surprise
that we deem equality saturation to be more extensible than SymPy, since the
very premise of equality saturation is based on providing a custom language,
rewrite rules, and analysis, while SymPy is designed specifically for symbolic
mathematics. However, this advantage of equality saturation also has a price:
Every extension needs to be reasoned about, implemented, vetted, and possibly
optimized. Meanwhile, SymPy is a well-suited tool for the purpose of solving
$unat$ and only needed to be integrated into our typechecking algorithm.

We also need to consider in which _direction_ we want to extend. For example,
our implementation of $udata$ is in principle agnostic over which datatypes it
unifies. Adapting it to other datatypes is as trivial as adding variants to the
internal language, and adding simple rewrite rules. But looking beyond what we
implemented in this work, we hinted at the necessity for constraints in #rise's
type system (@complete), for example inequalities such as "$b$ must be larger
than $4$". To our knowledge, SymPy does not support adding such constraints to
an equational system. Similarly, E-Graphs are not well-suited to reason about
inequalities. After all, E stands for equality.

// #q[doesn't feel done but i dont know what else to say.]








